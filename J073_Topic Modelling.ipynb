{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vqWPVEX5SyAe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "2leGCh3wSyCn",
    "outputId": "c0eb3180-7213-4fe7-a428-5b512ae38b80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e9aa7f02-2927-49b6-a0c3-c81340dd0351\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9aa7f02-2927-49b6-a0c3-c81340dd0351')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e9aa7f02-2927-49b6-a0c3-c81340dd0351 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e9aa7f02-2927-49b6-a0c3-c81340dd0351');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('papers.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Tas88YbXSyFb",
    "outputId": "bf16a435-c963-41d8-878c-daf40ac40dd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-71606a42-94f9-4e66-9025-8bf2c75fa2b4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71606a42-94f9-4e66-9025-8bf2c75fa2b4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-71606a42-94f9-4e66-9025-8bf2c75fa2b4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-71606a42-94f9-4e66-9025-8bf2c75fa2b4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                          paper_text  index\n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...      0\n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...      1\n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...      2\n",
       "3  Bayesian Query Construction for Neural\\nNetwor...      3\n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = data.paper_text, columns = ['paper_text'], index = range(len(data)))\n",
    "df['index'] = range(len(data))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsDm6rXFSyKn",
    "outputId": "eeea41ed-0dd8-4b83-b46b-996cfc494114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7241, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cS0LEyjESyNH",
    "outputId": "23083bcd-3da0-442c-a7b4-a2bf386a9e63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper_text    0\n",
       "index         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTZkjvfQVv4O"
   },
   "source": [
    "**Preprocessing -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BrkYKLG4Dj8v"
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOYqt4Z8VsNo",
    "outputId": "5dff73fa-ea52-40c7-f082-e833aef2dc34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bgvn139QVsQz"
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7FumY9xrVsT_"
   },
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos = 'v'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    result = []\n",
    "    for token in simple_preprocess(text):\n",
    "        if token not in STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxzPSSK6VsWv",
    "outputId": "b8af961d-12e5-4856-f6ea-80125649a673"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [self, organ, associ, databas, applic, hisashi...\n",
       "1     [mean, field, theori, layer, visual, cortex, a...\n",
       "2     [store, covari, associ, long, term, potenti, d...\n",
       "3     [bayesian, queri, construct, neural, network, ...\n",
       "4     [neural, network, ensembl, cross, valid, activ...\n",
       "5     [sing, neural, instanti, deform, model, christ...\n",
       "6     [plastic, mediat, competit, learn, terrenc, se...\n",
       "7     [iceg, morpholog, classif, analogu, vlsi, neur...\n",
       "8     [real, time, control, tokamak, plasma, neural,...\n",
       "9     [real, time, control, tokamak, plasma, neural,...\n",
       "10    [learn, play, game, chess, sebastian, thrun, u...\n",
       "11    [scale, data, cluster, thoma, hofmann, joachim...\n",
       "12    [experiment, comparison, recurr, neural, netwo...\n",
       "13    [train, multilay, perceptron, extend, kalman, ...\n",
       "14    [interfer, learn, intern, model, invers, dynam...\n",
       "Name: paper_text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = df['paper_text'].apply(preprocess_text)\n",
    "processed_docs[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI11Or1GFnfz"
   },
   "source": [
    "**Feature extraction through tf-idf-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HuD__UcKEZ6Q"
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wVGJvv7rEZ-C"
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3ZAbTg7BEaBR"
   },
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sbZcdOq3EaEU"
   },
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdRgQ7DJGDea"
   },
   "source": [
    "**Running LDA using tf-idf model -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Fu6Yt1peQTF7"
   },
   "outputs": [],
   "source": [
    "num_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "J91ZMeswF_4A"
   },
   "outputs": [],
   "source": [
    "lda_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics = num_topics, id2word = dictionary, passes = 2, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yoZtGZ-SF_7E",
    "outputId": "9b45cce3-85b2-4a89-f3f0-e2dce83bd58d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic : 0 \n",
      " Words 0.001*\"kernel\" + 0.001*\"imag\" + 0.001*\"cluster\" + 0.001*\"rank\" + 0.001*\"matrix\" + 0.001*\"label\" + 0.001*\"regret\" + 0.001*\"convex\" + 0.001*\"train\" + 0.001*\"graph\" \n",
      "\n",
      "Topic : 1 \n",
      " Words 0.001*\"imag\" + 0.001*\"neuron\" + 0.001*\"spike\" + 0.001*\"network\" + 0.001*\"layer\" + 0.001*\"train\" + 0.001*\"kernel\" + 0.001*\"polici\" + 0.001*\"tree\" + 0.001*\"action\" \n",
      "\n",
      "Topic : 2 \n",
      " Words 0.001*\"polici\" + 0.001*\"reward\" + 0.000*\"network\" + 0.000*\"action\" + 0.000*\"label\" + 0.000*\"classifi\" + 0.000*\"layer\" + 0.000*\"agent\" + 0.000*\"neuron\" + 0.000*\"loss\" \n",
      "\n",
      "Topic : 3 \n",
      " Words 0.001*\"polici\" + 0.001*\"imag\" + 0.001*\"cluster\" + 0.001*\"label\" + 0.001*\"reward\" + 0.001*\"kernel\" + 0.001*\"rank\" + 0.001*\"network\" + 0.001*\"queri\" + 0.001*\"train\" \n",
      "\n",
      "Topic : 4 \n",
      " Words 0.002*\"kernel\" + 0.001*\"imag\" + 0.001*\"cluster\" + 0.001*\"graph\" + 0.001*\"label\" + 0.001*\"polici\" + 0.001*\"classifi\" + 0.001*\"theorem\" + 0.001*\"network\" + 0.001*\"neuron\" \n",
      "\n",
      "Topic : 5 \n",
      " Words 0.001*\"neuron\" + 0.001*\"spike\" + 0.001*\"polici\" + 0.001*\"action\" + 0.001*\"imag\" + 0.001*\"agent\" + 0.001*\"kernel\" + 0.001*\"network\" + 0.001*\"layer\" + 0.001*\"cluster\" \n",
      "\n",
      "Topic : 6 \n",
      " Words 0.000*\"imag\" + 0.000*\"rank\" + 0.000*\"kernel\" + 0.000*\"item\" + 0.000*\"network\" + 0.000*\"norm\" + 0.000*\"loss\" + 0.000*\"train\" + 0.000*\"topic\" + 0.000*\"cluster\" \n",
      "\n",
      "Topic : 7 \n",
      " Words 0.002*\"neuron\" + 0.001*\"spike\" + 0.001*\"kernel\" + 0.001*\"network\" + 0.001*\"layer\" + 0.001*\"regret\" + 0.001*\"action\" + 0.001*\"train\" + 0.001*\"imag\" + 0.001*\"cell\" \n",
      "\n",
      "Topic : 8 \n",
      " Words 0.001*\"cluster\" + 0.001*\"graph\" + 0.001*\"neuron\" + 0.001*\"tree\" + 0.000*\"imag\" + 0.000*\"network\" + 0.000*\"train\" + 0.000*\"nois\" + 0.000*\"polici\" + 0.000*\"cell\" \n",
      "\n",
      "Topic : 9 \n",
      " Words 0.001*\"cluster\" + 0.001*\"topic\" + 0.001*\"network\" + 0.001*\"neuron\" + 0.001*\"imag\" + 0.001*\"word\" + 0.001*\"kernel\" + 0.001*\"train\" + 0.001*\"layer\" + 0.001*\"graph\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_tfidf.print_topics(-1):\n",
    "    print(f\"Topic : {idx} \\n Words {topic} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aihpZE_bktdf"
   },
   "source": [
    "**Common words between each pair of topics-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTVhS54DRGwt",
    "outputId": "c4323639-aeea-4668-9921-84c314ce507a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0.001*\"kernel\" + 0.001*\"imag\" + 0.001*\"cluster\" + 0.001*\"rank\" + 0.001*\"matrix\" + 0.001*\"label\" + 0.001*\"regret\" + 0.001*\"convex\" + 0.001*\"train\" + 0.001*\"graph\"',\n",
       " 1: '0.001*\"imag\" + 0.001*\"neuron\" + 0.001*\"spike\" + 0.001*\"network\" + 0.001*\"layer\" + 0.001*\"train\" + 0.001*\"kernel\" + 0.001*\"polici\" + 0.001*\"tree\" + 0.001*\"action\"',\n",
       " 2: '0.001*\"polici\" + 0.001*\"reward\" + 0.000*\"network\" + 0.000*\"action\" + 0.000*\"label\" + 0.000*\"classifi\" + 0.000*\"layer\" + 0.000*\"agent\" + 0.000*\"neuron\" + 0.000*\"loss\"',\n",
       " 3: '0.001*\"polici\" + 0.001*\"imag\" + 0.001*\"cluster\" + 0.001*\"label\" + 0.001*\"reward\" + 0.001*\"kernel\" + 0.001*\"rank\" + 0.001*\"network\" + 0.001*\"queri\" + 0.001*\"train\"',\n",
       " 4: '0.002*\"kernel\" + 0.001*\"imag\" + 0.001*\"cluster\" + 0.001*\"graph\" + 0.001*\"label\" + 0.001*\"polici\" + 0.001*\"classifi\" + 0.001*\"theorem\" + 0.001*\"network\" + 0.001*\"neuron\"',\n",
       " 5: '0.001*\"neuron\" + 0.001*\"spike\" + 0.001*\"polici\" + 0.001*\"action\" + 0.001*\"imag\" + 0.001*\"agent\" + 0.001*\"kernel\" + 0.001*\"network\" + 0.001*\"layer\" + 0.001*\"cluster\"',\n",
       " 6: '0.000*\"imag\" + 0.000*\"rank\" + 0.000*\"kernel\" + 0.000*\"item\" + 0.000*\"network\" + 0.000*\"norm\" + 0.000*\"loss\" + 0.000*\"train\" + 0.000*\"topic\" + 0.000*\"cluster\"',\n",
       " 7: '0.002*\"neuron\" + 0.001*\"spike\" + 0.001*\"kernel\" + 0.001*\"network\" + 0.001*\"layer\" + 0.001*\"regret\" + 0.001*\"action\" + 0.001*\"train\" + 0.001*\"imag\" + 0.001*\"cell\"',\n",
       " 8: '0.001*\"cluster\" + 0.001*\"graph\" + 0.001*\"neuron\" + 0.001*\"tree\" + 0.000*\"imag\" + 0.000*\"network\" + 0.000*\"train\" + 0.000*\"nois\" + 0.000*\"polici\" + 0.000*\"cell\"',\n",
       " 9: '0.001*\"cluster\" + 0.001*\"topic\" + 0.001*\"network\" + 0.001*\"neuron\" + 0.001*\"imag\" + 0.001*\"word\" + 0.001*\"kernel\" + 0.001*\"train\" + 0.001*\"layer\" + 0.001*\"graph\"'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dict = {}\n",
    "for idx, topic in lda_tfidf.print_topics(-1):\n",
    "    topic_dict[idx] = topic\n",
    "\n",
    "topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "T35zLBDNF_-G"
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "_hd0xJlzRZPm"
   },
   "outputs": [],
   "source": [
    "def topic_words(topic):\n",
    "    topics = re.findall(\"\\D{4,}\", topic)\n",
    "    return list(map(lambda x: x[2: x.find('\"', x.find('\"') + 1)], topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejCtg68ZGAAx",
    "outputId": "bab1c3e0-0d6a-465d-96cb-78f0a1b4171f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 and 1 : 3\n",
      "Common words - {'kernel', 'train', 'imag'}\n",
      "\n",
      "\n",
      "Topic 0 and 2 : 1\n",
      "Common words - {'label'}\n",
      "\n",
      "\n",
      "Topic 0 and 3 : 6\n",
      "Common words - {'cluster', 'kernel', 'label', 'train', 'rank', 'imag'}\n",
      "\n",
      "\n",
      "Topic 0 and 4 : 5\n",
      "Common words - {'cluster', 'kernel', 'label', 'graph', 'imag'}\n",
      "\n",
      "\n",
      "Topic 0 and 5 : 3\n",
      "Common words - {'cluster', 'kernel', 'imag'}\n",
      "\n",
      "\n",
      "Topic 0 and 6 : 5\n",
      "Common words - {'cluster', 'kernel', 'train', 'rank', 'imag'}\n",
      "\n",
      "\n",
      "Topic 0 and 7 : 4\n",
      "Common words - {'regret', 'kernel', 'train', 'imag'}\n",
      "\n",
      "\n",
      "Topic 0 and 8 : 4\n",
      "Common words - {'cluster', 'train', 'graph', 'imag'}\n",
      "\n",
      "\n",
      "Topic 0 and 9 : 5\n",
      "Common words - {'cluster', 'kernel', 'train', 'graph', 'imag'}\n",
      "\n",
      "\n",
      "Topic 1 and 2 : 5\n",
      "Common words - {'action', 'layer', 'polici', 'neuron', 'network'}\n",
      "\n",
      "\n",
      "Topic 1 and 3 : 5\n",
      "Common words - {'kernel', 'train', 'polici', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 1 and 4 : 5\n",
      "Common words - {'kernel', 'polici', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 1 and 5 : 8\n",
      "Common words - {'action', 'kernel', 'spike', 'layer', 'polici', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 1 and 6 : 4\n",
      "Common words - {'kernel', 'train', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 1 and 7 : 8\n",
      "Common words - {'action', 'kernel', 'train', 'spike', 'layer', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 1 and 8 : 6\n",
      "Common words - {'train', 'polici', 'tree', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 1 and 9 : 6\n",
      "Common words - {'kernel', 'train', 'layer', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 2 and 3 : 4\n",
      "Common words - {'label', 'reward', 'polici', 'network'}\n",
      "\n",
      "\n",
      "Topic 2 and 4 : 5\n",
      "Common words - {'label', 'polici', 'classifi', 'neuron', 'network'}\n",
      "\n",
      "\n",
      "Topic 2 and 5 : 6\n",
      "Common words - {'action', 'agent', 'layer', 'polici', 'neuron', 'network'}\n",
      "\n",
      "\n",
      "Topic 2 and 6 : 2\n",
      "Common words - {'loss', 'network'}\n",
      "\n",
      "\n",
      "Topic 2 and 7 : 4\n",
      "Common words - {'layer', 'action', 'neuron', 'network'}\n",
      "\n",
      "\n",
      "Topic 2 and 8 : 3\n",
      "Common words - {'polici', 'network', 'neuron'}\n",
      "\n",
      "\n",
      "Topic 2 and 9 : 3\n",
      "Common words - {'layer', 'neuron', 'network'}\n",
      "\n",
      "\n",
      "Topic 3 and 4 : 6\n",
      "Common words - {'cluster', 'kernel', 'label', 'polici', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 3 and 5 : 5\n",
      "Common words - {'cluster', 'kernel', 'polici', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 3 and 6 : 6\n",
      "Common words - {'cluster', 'kernel', 'train', 'rank', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 3 and 7 : 4\n",
      "Common words - {'kernel', 'train', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 3 and 8 : 5\n",
      "Common words - {'cluster', 'train', 'polici', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 3 and 9 : 5\n",
      "Common words - {'cluster', 'kernel', 'train', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 4 and 5 : 6\n",
      "Common words - {'cluster', 'kernel', 'polici', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 4 and 6 : 4\n",
      "Common words - {'cluster', 'kernel', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 4 and 7 : 4\n",
      "Common words - {'kernel', 'network', 'neuron', 'imag'}\n",
      "\n",
      "\n",
      "Topic 4 and 8 : 6\n",
      "Common words - {'cluster', 'polici', 'graph', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 4 and 9 : 6\n",
      "Common words - {'cluster', 'kernel', 'graph', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 5 and 6 : 4\n",
      "Common words - {'cluster', 'kernel', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 5 and 7 : 7\n",
      "Common words - {'action', 'kernel', 'spike', 'layer', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 5 and 8 : 5\n",
      "Common words - {'cluster', 'polici', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 5 and 9 : 6\n",
      "Common words - {'cluster', 'kernel', 'layer', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 6 and 7 : 4\n",
      "Common words - {'kernel', 'train', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 6 and 8 : 4\n",
      "Common words - {'cluster', 'train', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 6 and 9 : 6\n",
      "Common words - {'cluster', 'kernel', 'train', 'topic', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 7 and 8 : 5\n",
      "Common words - {'cell', 'train', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 7 and 9 : 6\n",
      "Common words - {'kernel', 'train', 'layer', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n",
      "Topic 8 and 9 : 6\n",
      "Common words - {'cluster', 'train', 'graph', 'neuron', 'network', 'imag'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for combination in combinations(list(range(10)), 2):\n",
    "    common_words = set(topic_words(topic_dict[combination[0]])).intersection(set(topic_words(topic_dict[combination[1]])))\n",
    "    print(f\"Topic {combination[0]} and {combination[1]} : {len(common_words)}\", end = \"\\n\")\n",
    "    print(f\"Common words - {common_words}\", end = \"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEcBydg3lokC"
   },
   "source": [
    "**Evaluating the topic model -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48zZou3YWG6m",
    "outputId": "f807a67c-564b-4479-d470-7723e5d2b1d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.20557733406454667\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_tfidf, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKrqJOr8n88P"
   },
   "source": [
    "Higher the coherence score , better it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sAtUVnroh2D"
   },
   "source": [
    "**Making a different model to get a higher coherence score -**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4VQnTfiubqb"
   },
   "source": [
    "Increasing the number of passes as well as the chunksize - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "I5bxKv4EWHOx"
   },
   "outputs": [],
   "source": [
    "lda_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics = num_topics, id2word = dictionary, passes = 15, workers = 4, \n",
    "                                       per_word_topics = True, chunksize = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7679UDO2WHRt",
    "outputId": "43947bf8-66ef-4b2b-fbc5-7453c36f487e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic : 0 \n",
      " Words 0.000*\"ssda\" + 0.000*\"spikernel\" + 0.000*\"parw\" + 0.000*\"srht\" + 0.000*\"micl\" + 0.000*\"jigsaw\" + 0.000*\"orda\" + 0.000*\"geopg\" + 0.000*\"glas\" + 0.000*\"hypercut\" \n",
      "\n",
      "Topic : 1 \n",
      " Words 0.000*\"pddp\" + 0.000*\"lissom\" + 0.000*\"dlda\" + 0.000*\"bnbp\" + 0.000*\"ferra\" + 0.000*\"universum\" + 0.000*\"pgpe\" + 0.000*\"gnkr\" + 0.000*\"cnsc\" + 0.000*\"despot\" \n",
      "\n",
      "Topic : 2 \n",
      " Words 0.000*\"ltsa\" + 0.000*\"knng\" + 0.000*\"advi\" + 0.000*\"adex\" + 0.000*\"lapsvm\" + 0.000*\"alphamax\" + 0.000*\"ohdp\" + 0.000*\"brnn\" + 0.000*\"pcca\" + 0.000*\"bmmf\" \n",
      "\n",
      "Topic : 3 \n",
      " Words 0.000*\"hyperalign\" + 0.000*\"copeland\" + 0.000*\"flic\" + 0.000*\"fascicl\" + 0.000*\"nonbacktrack\" + 0.000*\"lsir\" + 0.000*\"svcca\" + 0.000*\"ccmrfs\" + 0.000*\"akda\" + 0.000*\"bisubmodular\" \n",
      "\n",
      "Topic : 4 \n",
      " Words 0.002*\"kernel\" + 0.002*\"imag\" + 0.002*\"neuron\" + 0.002*\"cluster\" + 0.002*\"polici\" + 0.001*\"network\" + 0.001*\"spike\" + 0.001*\"train\" + 0.001*\"layer\" + 0.001*\"graph\" \n",
      "\n",
      "Topic : 5 \n",
      " Words 0.000*\"divmbest\" + 0.000*\"orrent\" + 0.000*\"mixer\" + 0.000*\"lgssm\" + 0.000*\"trbm\" + 0.000*\"diskmean\" + 0.000*\"psgd\" + 0.000*\"psom\" + 0.000*\"gaifman\" + 0.000*\"nestt\" \n",
      "\n",
      "Topic : 6 \n",
      " Words 0.000*\"spgp\" + 0.000*\"kbsf\" + 0.000*\"walkback\" + 0.000*\"trader\" + 0.000*\"dapt\" + 0.000*\"ddcrp\" + 0.000*\"ifat\" + 0.000*\"iwal\" + 0.000*\"deff\" + 0.000*\"escort\" \n",
      "\n",
      "Topic : 7 \n",
      " Words 0.000*\"pbil\" + 0.000*\"bruck\" + 0.000*\"adahedg\" + 0.000*\"pbay\" + 0.000*\"kbann\" + 0.000*\"leech\" + 0.000*\"isomer\" + 0.000*\"dude\" + 0.000*\"cmab\" + 0.000*\"groupsam\" \n",
      "\n",
      "Topic : 8 \n",
      " Words 0.000*\"strf\" + 0.000*\"gpfa\" + 0.000*\"tunley\" + 0.000*\"meiosi\" + 0.000*\"pcsa\" + 0.000*\"rpfb\" + 0.000*\"prpca\" + 0.000*\"eigenvoic\" + 0.000*\"mlle\" + 0.000*\"adag\" \n",
      "\n",
      "Topic : 9 \n",
      " Words 0.000*\"mirna\" + 0.000*\"parsec\" + 0.000*\"laprl\" + 0.000*\"kcsd\" + 0.000*\"trader\" + 0.000*\"gkdr\" + 0.000*\"sulu\" + 0.000*\"wfomc\" + 0.000*\"scsg\" + 0.000*\"mlfre\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_tfidf.print_topics(-1):\n",
    "    print(f\"Topic : {idx} \\n Words {topic} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "NcTB8q3IWHUk"
   },
   "outputs": [],
   "source": [
    "topic_dict = {}\n",
    "for idx, topic in lda_tfidf.print_topics(-1):\n",
    "    topic_dict[idx] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQBAcADRWHXZ",
    "outputId": "1b5d3d5f-71c6-4755-f9e9-4504639331db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 and 1 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 0 and 2 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 0 and 3 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 0 and 4 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 0 and 5 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 0 and 6 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 0 and 7 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 0 and 8 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 0 and 9 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 1 and 2 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 1 and 3 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 1 and 4 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 1 and 5 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 1 and 6 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 1 and 7 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 1 and 8 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 1 and 9 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 2 and 3 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 2 and 4 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 2 and 5 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 2 and 6 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 2 and 7 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 2 and 8 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 2 and 9 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 3 and 4 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 3 and 5 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 3 and 6 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 3 and 7 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 3 and 8 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 3 and 9 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 4 and 5 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 4 and 6 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 4 and 7 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 4 and 8 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 4 and 9 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 5 and 6 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 5 and 7 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 5 and 8 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 5 and 9 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 6 and 7 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 6 and 8 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 6 and 9 : 1\n",
      "Common words - {'trader'}\n",
      "\n",
      "\n",
      "Topic 7 and 8 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 7 and 9 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n",
      "Topic 8 and 9 : 0\n",
      "Common words - set()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for combination in combinations(list(range(10)), 2):\n",
    "    common_words = set(topic_words(topic_dict[combination[0]])).intersection(set(topic_words(topic_dict[combination[1]])))\n",
    "    print(f\"Topic {combination[0]} and {combination[1]} : {len(common_words)}\", end = \"\\n\")\n",
    "    print(f\"Common words - {common_words}\", end = \"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXIezk45pG47",
    "outputId": "3f04da33-fe30-4db7-b2b3-c99366752bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.613569520376584\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_tfidf, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QZan-KkpHU3"
   },
   "source": [
    "## Now , we can see that the topics have very little to none in common , which is indicated by the very less number of common words between all pairs of topics as well as by the high coherence score "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "J009_NLP_Asst2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
